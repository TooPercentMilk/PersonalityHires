{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWccHPa8100b",
        "outputId": "97d441c0-068f-4527-82db-45e96fdf8dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, DistilBertModel, DistilBertTokenizer\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 6\n",
        "is_textual_metadata = False\n",
        "is_numerical_metadata = False\n",
        "is_sentiment_scores = False\n",
        "\n",
        "\n",
        "class HybridBERTModel(nn.Module):\n",
        "    def __init__(self, num_classes, is_numerical_metadata, is_sentiment_scores):\n",
        "        super().__init__()\n",
        "\n",
        "        self.is_numerical_metadata = is_numerical_metadata\n",
        "        self.is_sentiment_scores = is_sentiment_scores\n",
        "\n",
        "        additional_neurons = 0\n",
        "        if self.is_numerical_metadata:\n",
        "          additional_neurons += 5\n",
        "\n",
        "        if self.is_sentiment_scores:\n",
        "          additional_neurons += 1\n",
        "\n",
        "\n",
        "\n",
        "        hidden_neurons = 768 + additional_neurons\n",
        "\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.pre_classifier = torch.nn.Linear(hidden_neurons, hidden_neurons)\n",
        "        self.activation = torch.nn.Tanh()\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(hidden_neurons, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask,  numerical_features = None, sentiment_scores = None):\n",
        "        distilbert_output = self.distilbert(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        hidden_state = distilbert_output[0]\n",
        "        pooled_output = hidden_state[:, 0]\n",
        "\n",
        "        combined_features = pooled_output\n",
        "        if numerical_features is not None and self.is_numerical_metadata:\n",
        "          combined_features = torch.cat((combined_features, numerical_features), dim = 1)\n",
        "\n",
        "        if sentiment_scores is not None and self.is_sentiment_scores:\n",
        "          combined_features = torch.cat((combined_features, sentiment_scores), dim = 1)\n",
        "\n",
        "        pre_classifier_activated_output = self.activation((self.pre_classifier(combined_features)))\n",
        "        dropout_output = self.dropout(pre_classifier_activated_output)\n",
        "        logits = self.classifier(dropout_output)\n",
        "\n",
        "        probs = F.softmax(logits, dim = 1)\n",
        "\n",
        "        cum_probs = torch.cumsum(probs, dim = 1)\n",
        "\n",
        "        return cum_probs"
      ],
      "metadata": {
        "id": "2Puau5T0uPSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyjPVUdVsITQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda5844e-a864-4ce7-f003-ba7bf89853be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_QpNBgTNyv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49712a8-2847-496d-97b0-0221405888e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HybridBERTModel(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (activation): Tanh()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = HybridBERTModel(num_classes, is_numerical_metadata, is_sentiment_scores)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYFbgCyTgz27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08fd84b-6033-4470-c7f4-67d3306a6205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-3f03c0fcb1be>:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dataset = TensorDataset(torch.tensor(tokenized['input_ids']), torch.tensor(tokenized['attention_mask']), torch.tensor(labels))\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = load_dataset(\"liar\")\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "sentiment_data, sentiment_mapping = None, None\n",
        "if model.is_sentiment_scores:\n",
        "  sentiment_data = pd.read_csv(\"drive/MyDrive/sentiment_dataset.csv\")\n",
        "  sentiment_mapping = dict(zip(sentiment_data['id'], sentiment_data['Sentiment']))\n",
        "\n",
        "def preprocess_data(examples, num_classes, is_textual_metadata, is_numerical_features, is_sentiment_scores):\n",
        "\n",
        "    def label_mapping(label_idx, num_classes):\n",
        "\n",
        "      actual_idx = [1, 3, 4, 5, 2, 0]\n",
        "\n",
        "      result = [float(0)] * num_classes\n",
        "\n",
        "      i = (actual_idx[label_idx]) // (6 // num_classes)\n",
        "\n",
        "      for idx in range(i, num_classes):\n",
        "        result[idx] = float(1)\n",
        "\n",
        "      return result\n",
        "\n",
        "\n",
        "    labels = list(map(lambda elem: label_mapping(elem, num_classes), examples['label']))\n",
        "\n",
        "    combined_text = [statement + \" This is what \" + speaker + \", a \" + party_affiliation + \", said on \" + subject + \".\"  for statement, speaker, subject, party_affiliation in zip(examples['statement'], examples['speaker'], examples['subject'], examples['party_affiliation'])]\n",
        "\n",
        "    text_to_tokenize = combined_text if is_textual_metadata else examples['statement']\n",
        "\n",
        "    tokenized = tokenizer(text_to_tokenize, padding= True, truncation=True, max_length=128, return_tensors = 'pt')\n",
        "\n",
        "    numerical_features = torch.rand((len(examples['label']), 5)) if is_numerical_features else None\n",
        "    sentiment_scores = None\n",
        "\n",
        "    if is_sentiment_scores:\n",
        "      sentiment_scores = [sentiment_mapping[statement_id] for statement_id in examples['id']]\n",
        "      sentiment_scores = [[1 if s == 'POSITIVE' else 0] for s in sentiment_scores]\n",
        "\n",
        "\n",
        "    result = None\n",
        "    if is_sentiment_scores and is_numerical_features:\n",
        "      result = tokenized, numerical_features, sentiment_scores, labels\n",
        "    elif is_sentiment_scores:\n",
        "      result = tokenized, sentiment_scores, labels\n",
        "    elif is_numerical_features:\n",
        "      result = tokenized, numerical_features, labels\n",
        "    else:\n",
        "      result = tokenized, labels\n",
        "\n",
        "\n",
        "    # numerical_features = torch.tensor([\n",
        "    #     examples['barely_true_counts'],\n",
        "    #     examples['false_counts'],\n",
        "    #     examples['half_true_counts'],\n",
        "    #     examples['mostly_true_counts'],\n",
        "    #     examples['pants_on_fire_counts']\n",
        "    # ]).t()\n",
        "\n",
        "    return result\n",
        "\n",
        "def create_dataset(dataset_split, num_classes, is_textual_metadata, is_numerical_features, is_sentiment_scores):\n",
        "    dataset = None\n",
        "\n",
        "    if is_sentiment_scores and is_numerical_features:\n",
        "        tokenized,  numerical_features, sentiment_scores, labels = preprocess_data(dataset_split, num_classes, is_textual_metadata, is_numerical_features, is_sentiment_scores)\n",
        "        dataset = TensorDataset(torch.tensor(tokenized['input_ids']), torch.tensor(tokenized['attention_mask']), torch.tensor(numerical_features), torch.tensor(sentiment_scores), torch.tensor(labels))\n",
        "    elif is_sentiment_scores:\n",
        "        tokenized, sentiment_scores, labels = preprocess_data(dataset_split, num_classes, is_textual_metadata, is_numerical_features, is_sentiment_scores)\n",
        "        dataset = TensorDataset(torch.tensor(tokenized['input_ids']), torch.tensor(tokenized['attention_mask']), torch.tensor(sentiment_scores), torch.tensor(labels))\n",
        "    elif is_numerical_features:\n",
        "        tokenized,  numerical_features, labels = preprocess_data(dataset_split, num_classes, is_textual_metadata, is_numerical_features, is_sentiment_scores)\n",
        "        dataset = TensorDataset(torch.tensor(tokenized['input_ids']), torch.tensor(tokenized['attention_mask']), torch.tensor(numerical_features), torch.tensor(labels))\n",
        "    else:\n",
        "        tokenized, labels = preprocess_data(dataset_split, num_classes, is_textual_metadata, is_numerical_features, is_sentiment_scores)\n",
        "        dataset = TensorDataset(torch.tensor(tokenized['input_ids']), torch.tensor(tokenized['attention_mask']), torch.tensor(labels))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_dataset = create_dataset(dataset['train'], num_classes, is_textual_metadata, is_numerical_metadata, is_sentiment_scores)\n",
        "val_dataset = create_dataset(dataset['validation'], num_classes, is_textual_metadata, is_numerical_metadata, is_sentiment_scores)\n",
        "test_dataset = create_dataset(dataset['test'], num_classes, is_textual_metadata, is_numerical_metadata, is_sentiment_scores)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "# ['false', 'half-true', 'mostly-true', 'True', 'barely-true', 'pants-fire']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBCELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        outputs = outputs.clamp(min= 0.0001, max= 0.9999)\n",
        "        loss = -1 * (targets * torch.log(outputs) + (1 - targets) * torch.log(1 - outputs))\n",
        "        return loss.mean()\n",
        "\n",
        "loss_fn = CustomBCELoss()"
      ],
      "metadata": {
        "id": "ssGGY1S4qUBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELfNuMZJJ6ZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7e1ae6-1134-4d49-8139-48b5371dc049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 506/642 [01:10<00:18,  7.44it/s]"
          ]
        }
      ],
      "source": [
        "best_val_accuracy = 0.0\n",
        "best_model_state_dict = None\n",
        "\n",
        "schedule = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma = 0.2)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(2):\n",
        "    model.train()  # Set the model to train mode\n",
        "    running_loss = 0\n",
        "    # Training loop\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids, attention_mask, numerical_features, sentiment_scores, labels = None, None, None, None, None\n",
        "\n",
        "\n",
        "        if model.is_sentiment_scores and model.is_numerical_metadata:\n",
        "            input_ids, attention_mask,  numerical_features, sentiment_scores, labels = batch\n",
        "            input_ids, attention_mask,  numerical_features, sentiment_scores, labels = input_ids.to(device), attention_mask.to(device), numerical_features.to(device), sentiment_scores.to(device), labels.to(device)\n",
        "        elif model.is_sentiment_scores:\n",
        "            input_ids, attention_mask, sentiment_scores, labels = batch\n",
        "            input_ids, attention_mask, sentiment_scores, labels = input_ids.to(device), attention_mask.to(device), sentiment_scores.to(device), labels.to(device)\n",
        "        elif model.is_numerical_metadata:\n",
        "            input_ids, attention_mask, numerical_features, labels = batch\n",
        "            input_ids, attention_mask, numerical_features, labels = input_ids.to(device), attention_mask.to(device), numerical_features.to(device), labels.to(device)\n",
        "        else:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model.forward(input_ids, attention_mask, numerical_features, sentiment_scores)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")\n",
        "    schedule.step()\n",
        "\n",
        "    \"\"\"\n",
        "    # Validation loop\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, numerical_features, sentiment_scores, labels = batch\n",
        "            input_ids, attention_mask, numerical_features, sentiment_scores, labels = input_ids.to(device), attention_mask.to(device), numerical_features.to(device), sentiment_scores.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model.forward(input_ids, attention_mask, numerical_features, sentiment_scores)\n",
        "\n",
        "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "    val_accuracy = correct_predictions / total_predictions\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "    # Save the model with the best validation accuracy\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        print(\"New best!\")\n",
        "        best_val_accuracy = val_accuracy\n",
        "        # best_model_state_dict = copy.deepcopy(model.state_dict())\n",
        "        best_model_state_dict = model.state_dict()\n",
        "    # print(compare_state_dicts(best_model_state_dict, model.state_dict()))\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the best model state_dict\n",
        "#model.load_state_dict(best_model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmHS8oVLGz6A"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "model_save_path = '/content/drive/MyDrive/news_bert_weights.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqqtQRWOiNpY"
      },
      "outputs": [],
      "source": [
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/news_bert_weights.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB6PZqVuiiR6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_probs(cums):\n",
        "    result = [cums[0]]\n",
        "    result.extend([cums[i] - cums[i - 1] for i in range(1, len(cums))])\n",
        "    return result\n",
        "\n",
        "def evaluate_model(model, testing_loader):\n",
        "    model.eval()\n",
        "    all_outputs, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in testing_loader:\n",
        "            input_ids, attention_mask,  numerical_features, sentiment_scores, labels = None, None, None, None, None\n",
        "            if model.is_sentiment_scores and model.is_numerical_metadata:\n",
        "                input_ids, attention_mask,  numerical_features, sentiment_scores, labels = batch\n",
        "                input_ids, attention_mask,  numerical_features, sentiment_scores, labels = input_ids.to(device), attention_mask.to(device), numerical_features.to(device), sentiment_scores.to(device), labels.to(device)\n",
        "            elif model.is_sentiment_scores:\n",
        "                input_ids, attention_mask, sentiment_scores, labels = batch\n",
        "                input_ids, attention_mask, sentiment_scores, labels = input_ids.to(device), attention_mask.to(device), sentiment_scores.to(device), labels.to(device)\n",
        "            elif model.is_numerical_metadata:\n",
        "                input_ids, attention_mask, numerical_features, labels = batch\n",
        "                input_ids, attention_mask, numerical_features, labels = input_ids.to(device), attention_mask.to(device), numerical_features.to(device), labels.to(device)\n",
        "            else:\n",
        "                input_ids, attention_mask, labels = batch\n",
        "                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            outputs = model.forward(input_ids, attention_mask, numerical_features, sentiment_scores)\n",
        "\n",
        "            output_probs = [get_probs(output) for output in outputs]\n",
        "            label_probs = [get_probs(label) for label in labels]\n",
        "\n",
        "            output_vals = torch.argmax(torch.tensor(output_probs), dim = 1)\n",
        "            label_vals = torch.argmax(torch.tensor(label_probs), dim = 1)\n",
        "            all_outputs.append(output_vals)\n",
        "            all_labels.append(label_vals)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs, dim = 0)\n",
        "    all_labels = torch.cat(all_labels, dim = 0)\n",
        "\n",
        "    accuracy = (all_outputs == all_labels).float().mean().item()\n",
        "\n",
        "    return all_outputs.float(), all_labels.float(), accuracy\n",
        "\n",
        "def weighted_ordinal_accuracy(y_true, y_pred, weight=0.5):\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    abs_diff = np.abs(y_true - y_pred)\n",
        "    mask = (abs_diff == 1) * weight\n",
        "    weighted_diff = np.dot(abs_diff, mask)\n",
        "    accuracy = (weighted_diff + np.sum(y_true == y_pred)) / len(y_true)\n",
        "    return accuracy\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    return torch.mean(torch.abs(y_true - y_pred)).item()\n",
        "\n",
        "def within_one_accuracy(y_true, y_pred):\n",
        "    return torch.mean((torch.abs(y_true - y_pred) <= 1).float()).item()\n",
        "\n",
        "\n",
        "\n",
        "training_accuracy = evaluate_model(model, train_loader)[2]\n",
        "y_true, y_pred, accuracy = evaluate_model(model, val_loader)\n",
        "ordinal_accuracy = weighted_ordinal_accuracy(y_true, y_pred)\n",
        "mean_absolute_error = mean_absolute_error(y_true, y_pred)\n",
        "within_one_accuracy = within_one_accuracy(y_true, y_pred)\n",
        "\n",
        "print(\"Training Accuracy\", training_accuracy)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "print('Validation Ordinal Accuracy:', ordinal_accuracy)\n",
        "print('Validation Mean Absolute Error:', mean_absolute_error)\n",
        "print('Within 1 Accuracy:', within_one_accuracy)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size = 16)\n",
        "y_true, y_pred, test_accuracy = evaluate_model(model, test_loader)\n",
        "test_ordinal_accuracy = weighted_ordinal_accuracy(y_true, y_pred)\n",
        "\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "print('Testing Ordinal Accuracy:', test_ordinal_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92WFXgrPGwuz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZzzxglfijOy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
