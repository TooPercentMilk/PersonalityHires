{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWccHPa8100b",
        "outputId": "937cd17e-d20a-4b2c-c983-a39f6f652339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, DistilBertModel, DistilBertTokenizer\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "is_textual_metadata = True\n",
        "\n",
        "class HybridBERTModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.pre_classifier = torch.nn.Linear(769, 769)\n",
        "        self.activation = torch.nn.Tanh()\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(769, num_classes)\n",
        "\n",
        "        \"\"\"\n",
        "        self.numerical_network = nn.Sequential(\n",
        "            nn.Linear(6, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask,  sentiment_score):\n",
        "        distilbert_output = self.distilbert(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        hidden_state = distilbert_output[0]\n",
        "        pooled_output = hidden_state[:, 0]\n",
        "        combined_features = torch.cat((pooled_output, sentiment_score), dim = 1)\n",
        "        pre_classifier_activated_output = self.activation((self.pre_classifier(combined_features)))\n",
        "        dropout_output = self.dropout(pre_classifier_activated_output)\n",
        "        logits = self.classifier(dropout_output)\n",
        "\n",
        "        probs = F.softmax(logits, dim = 1)\n",
        "\n",
        "        cum_probs = torch.cumsum(probs, dim = 1)\n",
        "\n",
        "        return cum_probs"
      ],
      "metadata": {
        "id": "2Puau5T0uPSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyjPVUdVsITQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb8005f-fac2-4736-bd76-ea8886ddba68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_QpNBgTNyv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e118363c-9313-4f90-d7ed-b3a4eec49915"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HybridBERTModel(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=769, out_features=769, bias=True)\n",
              "  (activation): Tanh()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=769, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model = HybridBERTModel(num_classes)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYFbgCyTgz27",
        "outputId": "850e83e9-edd0-449e-dcd7-592174e2e458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-e676102b33d0>:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(tokenized['input_ids']),\n",
            "<ipython-input-37-e676102b33d0>:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(tokenized['attention_mask']),\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = load_dataset(\"liar\")\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "sentiment_data = pd.read_csv(\"drive/MyDrive/sentiment_dataset.csv\")\n",
        "sentiment_mapping = dict(zip(sentiment_data['id'], sentiment_data['Sentiment']))\n",
        "\n",
        "def preprocess_data(examples, num_classes, is_textual_metadata):\n",
        "\n",
        "    def label_mapping(label_idx, num_classes):\n",
        "\n",
        "      actual_idx = [1, 3, 4, 5, 2, 0]\n",
        "\n",
        "      result = [float(0)] * num_classes\n",
        "\n",
        "      i = (actual_idx[label_idx]) // (6 // num_classes)\n",
        "\n",
        "      for idx in range(i, num_classes):\n",
        "        result[idx] = float(1)\n",
        "\n",
        "      return result\n",
        "\n",
        "\n",
        "    labels = list(map(lambda elem: label_mapping(elem, num_classes), examples['label']))\n",
        "\n",
        "    combined_text = [statement + \" This is what \" + speaker + \", a \" + party_affiliation + \", said on \" + subject + \".\"  for statement, speaker, subject, party_affiliation in zip(examples['statement'], examples['speaker'], examples['subject'], examples['party_affiliation'])]\n",
        "\n",
        "    text_to_tokenize = combined_text if is_textual_metadata else examples['statement']\n",
        "\n",
        "    tokenized = tokenizer(text_to_tokenize, padding= True, truncation=True, max_length=128, return_tensors = 'pt')\n",
        "\n",
        "    sentiment_scores = [sentiment_mapping[statement_id] for statement_id in examples['id']]\n",
        "    sentiment_scores = [[1 if s == 'POSITIVE' else 0] for s in sentiment_scores]\n",
        "\n",
        "    #numerical_features = torch.rand((len(examples['label']), 5)) # to exclude numerical features\n",
        "    # numerical_features = torch.tensor([\n",
        "    #     examples['barely_true_counts'],\n",
        "    #     examples['false_counts'],\n",
        "    #     examples['half_true_counts'],\n",
        "    #     examples['mostly_true_counts'],\n",
        "    #     examples['pants_on_fire_counts']\n",
        "    # ]).t()\n",
        "\n",
        "    return tokenized, sentiment_scores, labels\n",
        "\n",
        "def create_dataset(dataset_split, num_classes, is_textual_metadata):\n",
        "    tokenized,  sentiment_scores, labels = preprocess_data(dataset_split, num_classes, is_textual_metadata)\n",
        "    dataset = TensorDataset(\n",
        "        torch.tensor(tokenized['input_ids']),\n",
        "        torch.tensor(tokenized['attention_mask']),\n",
        "        torch.tensor(sentiment_scores),\n",
        "        torch.tensor(labels)\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "train_dataset = create_dataset(dataset['train'], num_classes, is_textual_metadata)\n",
        "val_dataset = create_dataset(dataset['validation'], num_classes, is_textual_metadata)\n",
        "test_dataset = create_dataset(dataset['test'], num_classes, is_textual_metadata)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "# ['false', 'half-true', 'mostly-true', 'True', 'barely-true', 'pants-fire']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBCELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        outputs = outputs.clamp(min= 0.0001, max= 0.9999)\n",
        "        loss = -1 * (targets * torch.log(outputs) + (1 - targets) * torch.log(1 - outputs))\n",
        "        return loss.mean()\n",
        "\n",
        "loss_fn = CustomBCELoss()"
      ],
      "metadata": {
        "id": "ssGGY1S4qUBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELfNuMZJJ6ZN",
        "outputId": "0d7f716d-8027-4c55-e791-1fc7fb08c236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 642/642 [01:37<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3981704230991851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 642/642 [01:36<00:00,  6.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.3415017523033968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "best_val_accuracy = 0.0\n",
        "best_model_state_dict = None\n",
        "\n",
        "schedule = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma = 0.2)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(2):\n",
        "    model.train()  # Set the model to train mode\n",
        "    running_loss = 0\n",
        "    # Training loop\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids, attention_mask, sentiment_scores, labels = batch\n",
        "        input_ids, attention_mask,  sentiment_scores, labels = input_ids.to(device), attention_mask.to(device), sentiment_scores.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model.forward(input_ids, attention_mask, sentiment_scores)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")\n",
        "    schedule.step()\n",
        "\n",
        "    \"\"\"\n",
        "    # Validation loop\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, numerical_features, sentiment_scores, labels = batch\n",
        "            input_ids, attention_mask, numerical_features, sentiment_scores, labels = input_ids.to(device), attention_mask.to(device), numerical_features.to(device), sentiment_scores.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model.forward(input_ids, attention_mask, numerical_features, sentiment_scores)\n",
        "\n",
        "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "    val_accuracy = correct_predictions / total_predictions\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "    # Save the model with the best validation accuracy\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        print(\"New best!\")\n",
        "        best_val_accuracy = val_accuracy\n",
        "        # best_model_state_dict = copy.deepcopy(model.state_dict())\n",
        "        best_model_state_dict = model.state_dict()\n",
        "    # print(compare_state_dicts(best_model_state_dict, model.state_dict()))\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the best model state_dict\n",
        "#model.load_state_dict(best_model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmHS8oVLGz6A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f4453973-51d5-42b8-d173-1d568e313bb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel_save_path = '/content/drive/MyDrive/news_bert_weights.pth'\\ntorch.save(model.state_dict(), model_save_path)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "\"\"\"\n",
        "model_save_path = '/content/drive/MyDrive/news_bert_weights.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqqtQRWOiNpY"
      },
      "outputs": [],
      "source": [
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/news_bert_weights.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB6PZqVuiiR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d096375-c88a-4bd7-81cf-60682b3f60c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy 0.6466062664985657\n",
            "Validation Accuracy: 0.4961059093475342\n",
            "Validation Ordinal Accuracy: 0.7017133956386293\n",
            "Validation Mean Absolute Error: 0.5965732336044312\n",
            "Within 1 Accuracy: 0.9073208570480347\n",
            "Testing Accuracy: 0.4988308548927307\n",
            "Testing Ordinal Accuracy: 0.6979734996102884\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_probs(cums):\n",
        "    result = [cums[0]]\n",
        "    result.extend([cums[i] - cums[i - 1] for i in range(1, len(cums))])\n",
        "    return result\n",
        "\n",
        "def evaluate_model(model, testing_loader):\n",
        "    model.eval()\n",
        "    all_outputs, all_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in testing_loader:\n",
        "            input_ids, attention_mask, sentiment_scores, targets = batch\n",
        "            input_ids, attention_mask, sentiment_scores, targets = input_ids.to(device), attention_mask.to(device), sentiment_scores.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, sentiment_scores)\n",
        "\n",
        "            output_probs = [get_probs(output) for output in outputs]\n",
        "            target_probs = [get_probs(target) for target in targets]\n",
        "\n",
        "            output_vals = torch.argmax(torch.tensor(output_probs), dim = 1)\n",
        "            target_vals = torch.argmax(torch.tensor(target_probs), dim = 1)\n",
        "            all_outputs.append(output_vals)\n",
        "            all_targets.append(target_vals)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs, dim = 0)\n",
        "    all_targets = torch.cat(all_targets, dim = 0)\n",
        "\n",
        "    accuracy = (all_outputs == all_targets).float().mean().item()\n",
        "\n",
        "    return all_outputs.float(), all_targets.float(), accuracy\n",
        "\n",
        "def weighted_ordinal_accuracy(y_true, y_pred, weight=0.5):\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    abs_diff = np.abs(y_true - y_pred)\n",
        "    mask = (abs_diff == 1) * weight\n",
        "    weighted_diff = np.dot(abs_diff, mask)\n",
        "    accuracy = (weighted_diff + np.sum(y_true == y_pred)) / len(y_true)\n",
        "    return accuracy\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    return torch.mean(torch.abs(y_true - y_pred)).item()\n",
        "\n",
        "def within_one_accuracy(y_true, y_pred):\n",
        "    return torch.mean((torch.abs(y_true - y_pred) <= 1).float()).item()\n",
        "\n",
        "\n",
        "\n",
        "training_accuracy = evaluate_model(model, train_loader)[2]\n",
        "y_true, y_pred, accuracy = evaluate_model(model, val_loader)\n",
        "ordinal_accuracy = weighted_ordinal_accuracy(y_true, y_pred)\n",
        "mean_absolute_error = mean_absolute_error(y_true, y_pred)\n",
        "within_one_accuracy = within_one_accuracy(y_true, y_pred)\n",
        "\n",
        "print(\"Training Accuracy\", training_accuracy)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "print('Validation Ordinal Accuracy:', ordinal_accuracy)\n",
        "print('Validation Mean Absolute Error:', mean_absolute_error)\n",
        "print('Within 1 Accuracy:', within_one_accuracy)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size = 16)\n",
        "y_true, y_pred, test_accuracy = evaluate_model(model, test_loader)\n",
        "test_ordinal_accuracy = weighted_ordinal_accuracy(y_true, y_pred)\n",
        "\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "print('Testing Ordinal Accuracy:', test_ordinal_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92WFXgrPGwuz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZzzxglfijOy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
